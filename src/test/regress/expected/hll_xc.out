create schema hll_senarios_xc;
set current_schema = hll_senarios_xc;
create table t_id(id int);
insert into t_id values(generate_series(1,500));
--------------CONTENTS--------------------
--     hyperloglog test cases
------------------------------------------
--1. hello world
--2. website traffic static senario
--3. data warehouse use case
--4. axx senario
--5. axx extended
------------------------------------------
------------------------------------------
-- 1. hello world
------------------------------------------
--- make a dummy table
create table helloworld (
        id              integer,
        set     hll
);
--- insert an empty hll
insert into helloworld(id, set) values (1, hll_empty());
--- add a hashed integer to the hll
update helloworld set set = hll_add(set, hll_hash_integer(12345)) where id = 1;
--- or add a hashed string to the hll
update helloworld set set = hll_add(set, hll_hash_text('hello world')) where id = 1;
--- get the cardinality of the hll
select hll_cardinality(set) from helloworld where id = 1;
 hll_cardinality 
-----------------
               2
(1 row)

drop table helloworld;
------------------------------------------
-- 2. website traffic static senario
------------------------------------------
-- generate data
create table traffic(weekday int ,id int);
insert into traffic select 1, id%100 from t_id;
insert into traffic select 2, id%200 from t_id;
insert into traffic select 3, id%300 from t_id;
insert into traffic select 4, id%400 from t_id;
insert into traffic select 5, id%500 from t_id;
insert into traffic select 6, id%600 from t_id;
insert into traffic select 7, id%700 from t_id;
-- table to store hll statistics
create table report(weekday int, users hll);
insert into report select weekday, hll_add_agg(hll_hash_integer(id)) from traffic group by weekday;
-- 1->100 2->200 3->300 4->400 5->500 6->500 7->500
select weekday, #hll_add_agg(hll_hash_integer(id)) as unique_users from traffic group by weekday order by weekday;
 weekday |   unique_users   
---------+------------------
       1 |              100
       2 | 200.217861303237
       3 |  301.76494508014
       4 | 400.862650860414
       5 | 502.626444091693
       6 | 502.626933349694
       7 | 502.626933349694
(7 rows)

-- should be around 500
select  #hll_union_agg(users) from report;
     ?column?     
------------------
 503.657946119357
(1 row)

drop table traffic;
drop table report;
------------------------------------------
-- 3. data warehouse use case
------------------------------------------
-- create table
create table facts (
	date            date,
	user_id         integer
);
-- generate date
insert into facts values ('2019-02-20', generate_series(1,100));
insert into facts values ('2019-02-21', generate_series(1,200));
insert into facts values ('2019-02-22', generate_series(1,300));
insert into facts values ('2019-02-23', generate_series(1,400));
insert into facts values ('2019-02-24', generate_series(1,500));
insert into facts values ('2019-02-25', generate_series(1,600));
insert into facts values ('2019-02-26', generate_series(1,700));
insert into facts values ('2019-02-27', generate_series(1,800));
-- create the destination table
create table daily_uniques (
    date            date UNIQUE,
    users           hll
);
NOTICE:  CREATE TABLE / UNIQUE will create implicit index "daily_uniques_date_key" for table "daily_uniques"
-- fill it with the aggregated unique statistics
INSERT INTO daily_uniques(date, users)
    SELECT date, hll_add_agg(hll_hash_integer(user_id))
    FROM facts
    GROUP BY 1;
-- ask for the cardinality of the hll for each day
SELECT date, hll_cardinality(users) FROM daily_uniques order by date;
           date           | hll_cardinality  
--------------------------+------------------
 Wed Feb 20 00:00:00 2019 |              100
 Thu Feb 21 00:00:00 2019 | 200.217913059312
 Fri Feb 22 00:00:00 2019 |  301.76494508014
 Sat Feb 23 00:00:00 2019 | 400.862858326446
 Sun Feb 24 00:00:00 2019 | 502.626933349694
 Mon Feb 25 00:00:00 2019 | 601.922606454213
 Tue Feb 26 00:00:00 2019 | 696.602316769498
 Wed Feb 27 00:00:00 2019 | 798.111731634412
(8 rows)

-- ask for one week uniques
SELECT hll_cardinality(hll_union_agg(users)) FROM daily_uniques WHERE date >= '2019-02-20'::date AND date <= '2019-02-26'::date;
 hll_cardinality  
------------------
 696.602316769498
(1 row)

-- or a sliding window of uniques over the past 6 days
SELECT date, #hll_union_agg(users) OVER seven_days
FROM daily_uniques
WINDOW seven_days AS (ORDER BY date ASC ROWS 6 PRECEDING);
           date           |     ?column?     
--------------------------+------------------
 Wed Feb 20 00:00:00 2019 |              100
 Thu Feb 21 00:00:00 2019 | 200.217913059312
 Fri Feb 22 00:00:00 2019 |  301.76494508014
 Sat Feb 23 00:00:00 2019 | 400.862858326446
 Sun Feb 24 00:00:00 2019 | 502.626933349694
 Mon Feb 25 00:00:00 2019 | 601.922606454213
 Tue Feb 26 00:00:00 2019 | 696.602316769498
 Wed Feb 27 00:00:00 2019 | 798.111731634412
(8 rows)

-- or the number of uniques you saw yesterday that you did not see today
SELECT date, (#hll_union_agg(users) OVER two_days) - #users AS lost_uniques
FROM daily_uniques
WINDOW two_days AS (ORDER BY date ASC ROWS 1 PRECEDING);
           date           | lost_uniques 
--------------------------+--------------
 Wed Feb 20 00:00:00 2019 |            0
 Thu Feb 21 00:00:00 2019 |            0
 Fri Feb 22 00:00:00 2019 |            0
 Sat Feb 23 00:00:00 2019 |            0
 Sun Feb 24 00:00:00 2019 |            0
 Mon Feb 25 00:00:00 2019 |            0
 Tue Feb 26 00:00:00 2019 |            0
 Wed Feb 27 00:00:00 2019 |            0
(8 rows)

drop table facts;
drop table daily_uniques;
------------------------------------------
-- 4. aqb test cases
------------------------------------------
create table test_hll(id bigint, name1 text, name2 text);
create table test_name1(id bigint, name1 hll);
create table test_name1_name2(id bigint, name1_name2 hll);
insert into test_hll select id, md5(id::text), md5(id::text) from t_id;
select hll_cardinality(hll_add_agg(hll_text)) , hll_cardinality(hll_add_agg(hll_bigint))
 from (
       select hll_hash_text(name1) hll_text,hll_hash_bigint(id) hll_bigint
         from test_hll
        union all
       select hll_hash_text(name1||name2) hll_text,hll_hash_bigint(id) hll_bigint
         from test_hll
      ) x;
 hll_cardinality  | hll_cardinality  
------------------+------------------
 995.709856341669 | 502.624949567292
(1 row)

select hll_cardinality(hll_union_agg(hll_add_value))
  from (
      select hll_add_agg(hll_hash_bigint(id)) hll_add_value
        from test_hll
       ) x;
 hll_cardinality  
------------------
 502.624949567292
(1 row)

select hll_cardinality(hll_union_agg(hll_add_value))
  from (
      select hll_add_agg(hll_hash_text(name1 || name2)) hll_add_value
        from test_hll
       ) x;
 hll_cardinality  
------------------
 496.450281194173
(1 row)

select hll_cardinality(hll_union_agg(hll_add_value))
  from (
      select hll_add_agg(hll_hash_text(name1 || name2)) hll_add_value
        from test_hll
	  union all
      select hll_add_agg(hll_hash_text(name1)) hll_add_value
        from test_hll
       ) x;
 hll_cardinality  
------------------
 995.709856341669
(1 row)

insert into test_name1
	select id, hll_add_agg(hll_hash_text(name1))
	from test_hll
	group by id;
select hll_cardinality(hll_union_agg(name1)) from test_name1;
 hll_cardinality  
------------------
 499.542425550241
(1 row)

insert into test_name1_name2
      select id, hll_add_agg(hll_hash_text(name1 || name2))
      from test_hll
	  group by id;
select hll_cardinality(hll_union_agg(name1_name2)) from test_name1_name2;
 hll_cardinality  
------------------
 496.450281194173
(1 row)

drop table test_hll;
drop table test_name1;
drop table test_name1_name2;
------------------------------------------
--  5. aqb extended test cases
------------------------------------------
create table t_data(a int, b int, c text , d text);
insert into t_data select mod(id,2), mod(id,3), id, id from t_id;
--create the dimentinon table
create table t_a_c_hll(a int, c hll);
create table t_a_cd_hll(a int, cd hll);
create table t_b_c_hll(b int, c hll);
create table t_b_cd_hll(b int, cd hll);
--insert the agg data
insert into t_a_c_hll select a, hll_add_agg(hll_hash_text(c)) from t_data group by a;
insert into t_a_cd_hll select a, hll_add_agg(hll_hash_text(c||d))  from t_data group by a;
insert into t_b_c_hll select b, hll_add_agg(hll_hash_text(c)) from t_data group by b;
insert into t_b_cd_hll select b, hll_add_agg(hll_hash_text(c||d))  from t_data group by b;
--group a have around 250
--group b have around 167
select a, #c from t_a_c_hll order by a;
 a |     ?column?     
---+------------------
 0 | 247.862354346299
 1 | 250.908710610377
(2 rows)

select a, #cd from t_a_cd_hll order by a;
 a |     ?column?     
---+------------------
 0 | 249.894992356239
 1 | 250.910160017494
(2 rows)

select b, #c from t_b_c_hll order by b;
 b |     ?column?     
---+------------------
 0 | 165.837309898492
 1 | 164.828002932655
 2 | 166.848221800016
(3 rows)

select b, #cd from t_b_cd_hll order by b;
 b |     ?column?     
---+------------------
 0 | 164.828159955429
 1 | 167.858709928037
 2 | 165.838429363155
(3 rows)

--should all be around 500
select #hll_union_agg(c) from t_a_c_hll;
     ?column?     
------------------
 498.496062953313
(1 row)

select #hll_union_agg(cd) from t_a_cd_hll;
     ?column?     
------------------
 499.540451882883
(1 row)

select #hll_union_agg(c) from t_b_c_hll;
     ?column?     
------------------
 498.496062953313
(1 row)

select #hll_union_agg(cd) from t_b_cd_hll;
     ?column?     
------------------
 499.540451882883
(1 row)

--prepare
prepare p1(int) as select a, hll_cardinality( hll_add_agg(hll_hash_text(c)) || hll_add_agg(hll_hash_text(d)) )from t_data where a = $1 group by a order by 1;
execute p1(0);
 a | hll_cardinality  
---+------------------
 0 | 247.862354346299
(1 row)

execute p1(1);
 a | hll_cardinality  
---+------------------
 1 | 250.908710610377
(1 row)

deallocate p1;
prepare p2(int) as select b, hll_cardinality( hll_add_agg(hll_hash_text(c)) || hll_add_agg(hll_hash_text(d)) )from t_data where b = $1 group by b order by 1;
execute p2(0);
 b | hll_cardinality  
---+------------------
 0 | 165.837309898492
(1 row)

execute p2(1);
 b | hll_cardinality  
---+------------------
 1 | 164.828002932655
(1 row)

execute p2(2);
 b | hll_cardinality  
---+------------------
 2 | 166.848221800016
(1 row)

deallocate p2;
--transaction
begin;
declare c cursor for  select a, hll_cardinality( hll_add_agg(hll_hash_text(c)) || hll_add_agg(hll_hash_text(d)) )from t_data group by a order by 1;
fetch next from c;
 a | hll_cardinality  
---+------------------
 0 | 247.862354346299
(1 row)

fetch next from c;
 a | hll_cardinality  
---+------------------
 1 | 250.908710610377
(1 row)

close c;
commit;
begin;
declare c cursor for  select b, hll_cardinality( hll_add_agg(hll_hash_text(c)) || hll_add_agg(hll_hash_text(d)) )from t_data group by b order by 1;
fetch next from c;
 b | hll_cardinality  
---+------------------
 0 | 165.837309898492
(1 row)

fetch next from c;
 b | hll_cardinality  
---+------------------
 1 | 164.828002932655
(1 row)

fetch next from c;
 b | hll_cardinality  
---+------------------
 2 | 166.848221800016
(1 row)

close c;
commit;
--cleaning up
drop table t_data;
drop table t_a_c_hll;
drop table t_a_cd_hll;
drop table t_b_c_hll;
drop table t_b_cd_hll;
--final cleaning
drop table t_id;
drop schema hll_senarios_xc cascade;
reset current_schema;
