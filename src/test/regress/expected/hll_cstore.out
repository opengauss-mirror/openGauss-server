create schema hll_cstore;
set current_schema = hll_cstore;
create table t_id(id int);
insert into t_id values(generate_series(1,5000));
--------------CONTENTS--------------------
--     hyperloglog test cases
------------------------------------------
--1. create table using hll type
--2. check cstore case--hello world
--2. check cstore case--website traffic static senario
--3. check cstore case--data warehouse use case
--4. check cstore case--axx senario
--5. check cstore case--axx extended
------------------------------------------
------------------------------------------
-- 1. create table
------------------------------------------
-- column store
create table t_hll(a int, b hll) with (orientation = column);
insert into t_hll select mod(id, 2) a, hll_add_agg(hll_hash_integer(id)) from t_id group by a;
select a, #b from t_hll order by 1;
 a |     ?column?     
---+------------------
 0 | 2519.69162884915
 1 | 2500.80095566789
(2 rows)

drop table t_hll;
-- row store
create table t_hll(a int, b hll);
insert into t_hll select mod(id, 2) a, hll_add_agg(hll_hash_integer(id)) from t_id group by a;
select a, #b from t_hll order by 1;
 a |     ?column?     
---+------------------
 0 | 2519.69162884915
 1 | 2500.80095566789
(2 rows)

drop table t_hll;
------------------------------------------
-- 2. check cstore case--hello world
------------------------------------------
--- make a dummy table
create table helloworld (
        id              integer,
        set     hll
) with (orientation = column);
--- insert an empty hll
insert into helloworld(id, set) values (1, hll_empty());
--- add a hashed integer to the hll
update helloworld set set = hll_add(set, hll_hash_integer(12345)) where id = 1;
--- or add a hashed string to the hll
update helloworld set set = hll_add(set, hll_hash_text('hello world')) where id = 1;
--- get the cardinality of the hll
select hll_cardinality(set) from helloworld where id = 1;
 hll_cardinality 
-----------------
               2
(1 row)

drop table helloworld;
------------------------------------------
-- 3. check cstore case--website traffic static senario
------------------------------------------
-- generate data
create table traffic(weekday int ,id int) with (orientation = column);
insert into traffic select 1, id%1000 from t_id;
insert into traffic select 2, id%2000 from t_id;
insert into traffic select 3, id%3000 from t_id;
insert into traffic select 4, id%4000 from t_id;
insert into traffic select 5, id%5000 from t_id;
insert into traffic select 6, id%6000 from t_id;
insert into traffic select 7, id%7000 from t_id;
-- table to store hll statistics
create table report(weekday int, users hll) with (orientation = column);
insert into report select weekday, hll_add_agg(hll_hash_integer(id)) from traffic group by weekday;
-- 1->1000 2->2000 3->3000 4->4000 5->5000 6->5000 7->5000
select weekday, #hll_add_agg(hll_hash_integer(id)) as unique_users from traffic group by weekday order by weekday;
 weekday |   unique_users   
---------+------------------
       1 | 996.685300786901
       2 | 1989.86749211873
       3 | 2983.25277563959
       4 | 4003.86165036395
       5 | 5034.89012432268
       6 | 5034.89012432268
       7 | 5034.89012432268
(7 rows)

-- should be around 5000
select  #hll_union_agg(users) from report;
     ?column?     
------------------
 5036.22316829936
(1 row)

drop table traffic;
drop table report;
------------------------------------------
-- 4. check cstore case--data warehouse use case
------------------------------------------
-- create table
create table facts (
	date            date,
	user_id         integer
) with (orientation = column);
-- generate date
insert into facts values ('2019-02-20', generate_series(1,100));
insert into facts values ('2019-02-21', generate_series(1,200));
insert into facts values ('2019-02-22', generate_series(1,300));
insert into facts values ('2019-02-23', generate_series(1,400));
insert into facts values ('2019-02-24', generate_series(1,500));
insert into facts values ('2019-02-25', generate_series(1,600));
insert into facts values ('2019-02-26', generate_series(1,700));
insert into facts values ('2019-02-27', generate_series(1,800));
-- create the destination table
create table daily_uniques (
    date            date,
    users           hll
) with (orientation = column);
-- fill it with the aggregated unique statistics
INSERT INTO daily_uniques(date, users)
    SELECT date, hll_add_agg(hll_hash_integer(user_id))
    FROM facts
    GROUP BY 1;
-- ask for the cardinality of the hll for each day
SELECT date, hll_cardinality(users) FROM daily_uniques order by date;	
           date           | hll_cardinality  
--------------------------+------------------
 Wed Feb 20 00:00:00 2019 |              100
 Thu Feb 21 00:00:00 2019 | 200.217913059312
 Fri Feb 22 00:00:00 2019 |  301.76494508014
 Sat Feb 23 00:00:00 2019 | 400.862858326446
 Sun Feb 24 00:00:00 2019 | 502.626933349694
 Mon Feb 25 00:00:00 2019 | 601.922606454213
 Tue Feb 26 00:00:00 2019 | 696.602316769498
 Wed Feb 27 00:00:00 2019 | 798.111731634412
(8 rows)

-- ask for one week uniques
SELECT hll_cardinality(hll_union_agg(users)) FROM daily_uniques WHERE date >= '2019-02-20'::date AND date <= '2019-02-26'::date;
 hll_cardinality  
------------------
 696.602316769498
(1 row)

-- or a sliding window of uniques over the past 6 days
SELECT date, #hll_union_agg(users) OVER seven_days
FROM daily_uniques
WINDOW seven_days AS (ORDER BY date ASC ROWS 6 PRECEDING);
           date           |     ?column?     
--------------------------+------------------
 Wed Feb 20 00:00:00 2019 |              100
 Thu Feb 21 00:00:00 2019 | 200.217913059312
 Fri Feb 22 00:00:00 2019 |  301.76494508014
 Sat Feb 23 00:00:00 2019 | 400.862858326446
 Sun Feb 24 00:00:00 2019 | 502.626933349694
 Mon Feb 25 00:00:00 2019 | 601.922606454213
 Tue Feb 26 00:00:00 2019 | 696.602316769498
 Wed Feb 27 00:00:00 2019 | 798.111731634412
(8 rows)

-- or the number of uniques you saw yesterday that you did not see today
SELECT date, (#hll_union_agg(users) OVER two_days) - #users AS lost_uniques
FROM daily_uniques
WINDOW two_days AS (ORDER BY date ASC ROWS 1 PRECEDING);	
           date           | lost_uniques 
--------------------------+--------------
 Wed Feb 20 00:00:00 2019 |            0
 Thu Feb 21 00:00:00 2019 |            0
 Fri Feb 22 00:00:00 2019 |            0
 Sat Feb 23 00:00:00 2019 |            0
 Sun Feb 24 00:00:00 2019 |            0
 Mon Feb 25 00:00:00 2019 |            0
 Tue Feb 26 00:00:00 2019 |            0
 Wed Feb 27 00:00:00 2019 |            0
(8 rows)

drop table facts;
drop table daily_uniques;
------------------------------------------
-- 5. check cstore case--aqb test cases
------------------------------------------
create table test_hll(id bigint, name1 text, name2 text) with (orientation = column);
create table test_name1(id bigint, name1 hll) with (orientation = column);
create table test_name1_name2(id bigint, name1_name2 hll) with (orientation = column);
insert into test_hll select id, md5(id::text), md5(id::text) from t_id;
select hll_cardinality(hll_add_agg(hll_text)) , hll_cardinality(hll_add_agg(hll_bigint)) 
 from (
       select hll_hash_text(name1) hll_text,hll_hash_bigint(id) hll_bigint 
         from test_hll 
        union all 
       select hll_hash_text(name1||name2) hll_text,hll_hash_bigint(id) hll_bigint 
         from test_hll
      ) x;
 hll_cardinality  | hll_cardinality  
------------------+------------------
 10010.6991959748 | 5001.88168550794
(1 row)

	  
select hll_cardinality(hll_union_agg(hll_add_value))
  from (
      select hll_add_agg(hll_hash_bigint(id)) hll_add_value
        from test_hll
       ) x;
 hll_cardinality  
------------------
 5001.88168550794
(1 row)

select hll_cardinality(hll_union_agg(hll_add_value))
  from (
      select hll_add_agg(hll_hash_text(name1 || name2)) hll_add_value
        from test_hll
       ) x;
 hll_cardinality 
-----------------
 5012.6502075377
(1 row)

select hll_cardinality(hll_union_agg(hll_add_value))
  from (
      select hll_add_agg(hll_hash_text(name1 || name2)) hll_add_value
        from test_hll
	  union all
      select hll_add_agg(hll_hash_text(name1)) hll_add_value
        from test_hll	  
       ) x;
 hll_cardinality  
------------------
 10010.6991959748
(1 row)

insert into test_name1 
	select id, hll_add_agg(hll_hash_text(name1))
	from test_hll
	group by id;
select hll_cardinality(hll_union_agg(name1)) from test_name1;
 hll_cardinality  
------------------
 4995.20839966803
(1 row)

insert into test_name1_name2
      select id, hll_add_agg(hll_hash_text(name1 || name2))
      from test_hll
	  group by id;
select hll_cardinality(hll_union_agg(name1_name2)) from test_name1_name2;
 hll_cardinality 
-----------------
 5012.6502075377
(1 row)

drop table test_hll;
drop table test_name1;
drop table test_name1_name2;
------------------------------------------
--  6. check cstore case--aqb extended test cases
------------------------------------------
create table t_data(a int, b int, c text , d text) with (orientation = column);
insert into t_data select mod(id,2), mod(id,3), id, id from t_id;
--create the dimentinon table
create table t_a_c_hll(a int, c hll) with (orientation = column);
create table t_a_cd_hll(a int, cd hll) with (orientation = column);
create table t_b_c_hll(b int, c hll) with (orientation = column);
create table t_b_cd_hll(b int, cd hll) with (orientation = column);
--insert the agg data
insert into t_a_c_hll select a, hll_add_agg(hll_hash_text(c)) from t_data group by a;
insert into t_a_cd_hll select a, hll_add_agg(hll_hash_text(c||d))  from t_data group by a;
insert into t_b_c_hll select b, hll_add_agg(hll_hash_text(c)) from t_data group by b;
insert into t_b_cd_hll select b, hll_add_agg(hll_hash_text(c||d))  from t_data group by b;
--group a have around 2500
--group b have around 1667
select a, #c from t_a_c_hll order by a;
 a |     ?column?     
---+------------------
 0 | 2500.38427539288
 1 | 2493.13651597733
(2 rows)

select a, #cd from t_a_cd_hll order by a;
 a |     ?column?     
---+------------------
 0 | 2516.87509627641
 1 | 2484.38383057192
(2 rows)

select b, #c from t_b_c_hll order by b;
 b |     ?column?     
---+------------------
 0 | 1638.31859048291
 1 | 1669.32807147884
 2 | 1667.09764591797
(3 rows)

select b, #cd from t_b_cd_hll order by b;
 b |     ?column?     
---+------------------
 0 | 1659.33032611596
 1 | 1662.60272065549
 2 | 1670.38421978935
(3 rows)

--should all be around 5000
select #hll_union_agg(c) from t_a_c_hll;
     ?column?     
------------------
 4988.65517013726
(1 row)

select #hll_union_agg(cd) from t_a_cd_hll;
     ?column?     
------------------
 4967.36909301632
(1 row)

select #hll_union_agg(c) from t_b_c_hll;
     ?column?     
------------------
 4988.65517013726
(1 row)

select #hll_union_agg(cd) from t_b_cd_hll;
     ?column?     
------------------
 4967.36909301632
(1 row)

--prepare
prepare p1(int) as select a, hll_cardinality( hll_add_agg(hll_hash_text(c)) || hll_add_agg(hll_hash_text(d)) )from t_data where a = $1 group by a order by 1;
execute p1(0);
 a | hll_cardinality  
---+------------------
 0 | 2500.38427539288
(1 row)

execute p1(1);
 a | hll_cardinality  
---+------------------
 1 | 2493.13651597733
(1 row)

deallocate p1;
prepare p2(int) as select b, hll_cardinality( hll_add_agg(hll_hash_text(c)) || hll_add_agg(hll_hash_text(d)) )from t_data where b = $1 group by b order by 1;
execute p2(0);
 b | hll_cardinality  
---+------------------
 0 | 1638.31859048291
(1 row)

execute p2(1);
 b | hll_cardinality  
---+------------------
 1 | 1669.32807147884
(1 row)

execute p2(2);
 b | hll_cardinality  
---+------------------
 2 | 1667.09764591797
(1 row)

deallocate p2;
--transaction
begin;
declare c cursor for  select a, hll_cardinality( hll_add_agg(hll_hash_text(c)) || hll_add_agg(hll_hash_text(d)) )from t_data group by a order by 1;
fetch next from c;
 a | hll_cardinality  
---+------------------
 0 | 2500.38427539288
(1 row)

fetch next from c;
 a | hll_cardinality  
---+------------------
 1 | 2493.13651597733
(1 row)

close c;
commit;
begin;
declare c cursor for  select b, hll_cardinality( hll_add_agg(hll_hash_text(c)) || hll_add_agg(hll_hash_text(d)) )from t_data group by b order by 1;
fetch next from c;
 b | hll_cardinality  
---+------------------
 0 | 1638.31859048291
(1 row)

fetch next from c;
 b | hll_cardinality  
---+------------------
 1 | 1669.32807147884
(1 row)

fetch next from c;
 b | hll_cardinality  
---+------------------
 2 | 1667.09764591797
(1 row)

close c;
commit;
--cleaning up
drop table t_data;
drop table t_a_c_hll;
drop table t_a_cd_hll;
drop table t_b_c_hll;
drop table t_b_cd_hll;
--final cleaning
drop table t_id;
drop schema hll_cstore cascade;
reset current_schema;
